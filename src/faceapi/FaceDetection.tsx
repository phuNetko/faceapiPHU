import React, { useEffect, useRef, useState } from "react";
import * as faceapi from "@vladmandic/face-api";
import { FaCamera } from "react-icons/fa";
import { FaDeleteLeft } from "react-icons/fa6";
import { setIsLoading } from "../store/statusSlice";
import { useDispatch, useSelector } from "react-redux";
import { RootState } from "../store/store";
import { toastError, toastInfo, toastSuccess, toastWarning } from "../ultils/toast";
import { ToastContainer } from "react-toastify";
import { checkLiveness } from "../ultils/checkFakeFace";
const loadModels = async () => {
  try {
    console.log("‚è≥ ƒêang t·∫£i models...");
    await faceapi.nets.tinyFaceDetector.loadFromUri("/models").catch((error) => {
      console.error("‚ùå L·ªói khi t·∫£i tinyFaceDetector:", error);
    });
    await faceapi.nets.ssdMobilenetv1.loadFromUri("/models").catch((error) => {
      console.error("‚ùå L·ªói khi t·∫£i ssdMobilenetv1:", error);
    });
    await faceapi.nets.faceLandmark68Net.loadFromUri("/models").catch((error) => {
      console.error("‚ùå L·ªói khi t·∫£i faceLandmark68Net:", error);
    });
    await faceapi.nets.faceRecognitionNet.loadFromUri("/models").catch((error) => {
      console.error("‚ùå L·ªói khi t·∫£i faceRecognitionNet:", error);
    });
    console.log("‚úÖ Models loaded successfully!");
  } catch (error) {
    console.error("‚ùå L·ªói khi t·∫£i models:", error);
  } finally {
  }
};
const FaceDetection: React.FC<{isRegister: boolean }> = ({ isRegister }) => {
  const isOpen = useSelector((state: RootState) => state.statusApp.isOpenVideo);
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [faceVector, setFaceVector] = useState<number[] | null>(null);
  const [name, setName] = useState("");
  const [matchedName, setMatchedName] = useState<string | null>(null);
  const dispatch = useDispatch();
  const streamRef = useRef<MediaStream | null>(null);
  const intervalRef = useRef<number | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  useEffect(() => {
    const startVideo = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 400, height: 400 } });
        streamRef.current = stream;
        if (videoRef.current) videoRef.current.srcObject = stream;
      } catch (error) {
        console.error("‚ùå L·ªói khi m·ªü camera:", error);
      }
    };

    const stopVideo = () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
        intervalRef.current = null;
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
    };

    const detectFaces = async () => {
      if (!videoRef.current || !canvasRef.current) return;
      const video = videoRef.current;
      const canvas = canvasRef.current;
      
      video.addEventListener("loadeddata", async () => {
        console.log("üì∏ Camera ƒë√£ s·∫µn s√†ng!");
        const displaySize = { width: video.videoWidth, height: video.videoHeight };
        faceapi.matchDimensions(canvas, displaySize);

        const detectAndDraw = async () => {
          if (!video || !canvas) return;
          
          const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
          const resizedDetections = faceapi.resizeResults(detections, displaySize);

          const ctx = canvas.getContext("2d");
          if (ctx) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            resizedDetections.forEach((detection) => {
              const { x, y, width, height } = detection.box;
              const cornerSize = 30;
              ctx.strokeStyle = "rgba(52, 173, 218, 0.9)";
              ctx.lineWidth = 10;
              ctx.shadowColor = "rgba(0, 0, 0, 1)";
              ctx.shadowBlur = 10;
              ctx.beginPath();
              ctx.moveTo(x, y + cornerSize - 50);
              ctx.lineTo(x, y - 50);
              ctx.lineTo(x + cornerSize, y - 50);
              ctx.moveTo(x + width - cornerSize, y - 50);
              ctx.lineTo(x + width, y - 50);
              ctx.lineTo(x + width, y + cornerSize - 50);
              ctx.moveTo(x + width, y + height - cornerSize - 50);
              ctx.lineTo(x + width, y + height - 50);
              ctx.lineTo(x + width - cornerSize, y + height - 50);
              ctx.moveTo(x + cornerSize, y + height - 50);
              ctx.lineTo(x, y + height - 50);
              ctx.lineTo(x, y + height - cornerSize - 50);
              ctx.stroke();
              ctx.closePath();
            });
          }
          animationFrameRef.current = requestAnimationFrame(detectAndDraw);
        };
        // S·ª≠ d·ª•ng requestAnimationFrame thay v√¨ setInterval
        detectAndDraw();
      });
    };

    if (isOpen) {
      try {
        dispatch(setIsLoading(true));
        loadModels().then(() => {
          startVideo().then(detectFaces);
        });
      } catch (error) {
        console.error("‚ùå L·ªói khi t·∫£i models:", error);
      } finally {
        dispatch(setIsLoading(false));
      }
    } else {
      stopVideo();
    }

    return () => {
      stopVideo();
    };
  }, [isOpen]);

  const captureFace = async () => {
    if (!videoRef.current) return;
    if (name == "") {
      toastError("‚ùå Vui l√≤ng nh·∫≠p t√™n!")();
      return;
    }
    try {
      dispatch(setIsLoading(true));
      await new Promise((resolve) => setTimeout(resolve, 50));
      const detections = await faceapi
        .detectSingleFace(videoRef.current)
        .withFaceLandmarks()
        .withFaceDescriptor();
      if (detections) {
        const vector = Array.from(detections.descriptor);
        setFaceVector(vector);
        const storedData = JSON.parse(localStorage.getItem("faceData") || "[]");
        const newData = [...storedData, { name, faceVector: vector }];
        localStorage.setItem("faceData", JSON.stringify(newData));
        toastSuccess("ƒê√£ th√™m khu√¥n m·∫∑t th√†nh c√¥ng!!!")();
        setName('')
      } else {
        toastWarning("Vui l√≤ng ƒë∆∞a khu√¥n m·∫∑t v√†o gi·ªØa khung h√¨nh!")();
      }
    } catch (error) {
      console.error("‚ùå L·ªói khi l∆∞u d·ªØ li·ªáu:", error);
      dispatch(setIsLoading(false));
    } finally {
      dispatch(setIsLoading(false));
    }
  };

  const compareFace = async () => {
    if (!videoRef.current) return;
    toastInfo("üîç Vui l√≤ng di c·ª≠ ƒë·ªông nh·∫π khu√¥n m·∫∑t trong kho·∫£ng 2s")();
    try {
      dispatch(setIsLoading(true));
      const isLive = await checkLiveness(videoRef.current);
      if (!isLive) {
        toastWarning("üö® Ph√°t hi·ªán ·∫£nh tƒ©nh! D·ª´ng qu√° tr√¨nh ƒëƒÉng k√Ω.")();
        return;
      }
      console.log("‚úÖ Liveness check th√†nh c√¥ng! Ti·∫øn h√†nh qu√©t khu√¥n m·∫∑t...");
      const detections = await faceapi
        .detectSingleFace(videoRef.current)
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detections) {
        toastError("‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t!")();
        return;
      }

      const faceVector = detections.descriptor;
      const storedData = JSON.parse(localStorage.getItem("faceData") || "[]");

      if (!storedData.length) {
        toastWarning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t n√†o ƒë·ªÉ so s√°nh!")();
        return;
      }

      let bestMatch = null;
      let minDistance = Infinity;

      storedData.forEach((item: { name: string; faceVector: number[] }) => {
        const distance = faceapi.euclideanDistance(faceVector, item.faceVector);
        console.log(`üîç Kho·∫£ng c√°ch v·ªõi ${item.name}:`, distance);

        if (distance < minDistance && distance < 0.5) { // 0.5 l√† ng∆∞·ª°ng nh·∫≠n di·ªán
          minDistance = distance;
          bestMatch = item.name;
        }
      });

      if (bestMatch) {
        setMatchedName(bestMatch);
        toastSuccess(`‚úÖ Nh·∫≠n di·ªán th√†nh c√¥ng: ${bestMatch}`)();
      } else {
        setMatchedName(null);
        toastError("‚ùå Kh√¥ng kh·ªõp v·ªõi ai trong d·ªØ li·ªáu!")();
      }
    } catch (error) {
      console.error("‚ùå L·ªói khi so s√°nh khu√¥n m·∫∑t:", error);
    } finally {
      dispatch(setIsLoading(false));
    }
  };
  const deleteData = () => {
    dispatch(setIsLoading(true));
    localStorage.removeItem("faceData");
    if (localStorage.getItem("faceData") == null) {
      toastSuccess("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x√≥a!")();
    }
    dispatch(setIsLoading(false));
  };

  return (
    <div className="relative top-0 right-0 left-0 bottom-0 z-50 w-[600px] h-[620px] flex justify-center flex-col gap-3 items-center bg-white rounded-md ">
      <div className="relative w-[350px] h-[350px] rounded-full flex-shrink-0 overflow-hidden">
        <video ref={videoRef} autoPlay muted className="absolute left-1/2 top-[-50%] -translate-x-1/2 translate-y-1/2 w-full h-full  scale-x-[-1]" />
        <canvas ref={canvasRef} className="absolute left-1/2 top-[-50%] -translate-x-1/2 translate-y-1/2 w-full h-full  scale-x-[-1] z-100" />
      </div>
      <div className="flex justify-center flex-col items-center gap-3">
        <input
          type="text"
          placeholder="Enter your name"
          value={name}
          onChange={(e) => setName(e.target.value)}
          className="w-full h-full px-3 py-2 pl-0.5 outline-none border-b-2 border-black"
        />
        <button onClick={isRegister ? captureFace : compareFace} className=" w-auto px-5 py-2 cursor-pointer hover:bg-gray-100 hover:text-[#34addacc] font-medium bg-white rounded-full flex justify-center gap-2 items-center border-solid transition-all duration-100 hover:shadow-md">
          <span>{isRegister ? "Register" : "Compare"}</span>
          <FaCamera />
        </button>
        <button onClick={deleteData} className=" w-auto px-5 py-2 cursor-pointer hover:bg-gray-100 hover:text-red-500 font-medium bg-white rounded-full flex justify-center gap-2 items-center border-solid transition-all duration-100 hover:shadow-md">
          <span>Delete Data</span>
          <FaDeleteLeft />
        </button>
      </div>
      <ToastContainer className='z-[99999999]' />
    </div>
  );
};

export default FaceDetection;
